#!/usr/bin/env python
# In project imports
import srp_md
from srp_md import learn, sense, srp_md_log

# Ros imports
import rospy

# Python imports
import logging
import argparse
import sys
import random
import csv
from datetime import datetime
import time
import multiprocessing
import Queue

# Get a logger
logger = logging.getLogger('srp_md')
logger.setLevel(logging.INFO)

# Global locks
file_lock = multiprocessing.Lock()


def str2bool(v):
    if isinstance(v, bool):
        return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')


def parse_args():
    """
    Parse input arguments
    """
    parser = argparse.ArgumentParser(description='Run block world experiment')

    # Main arguments, used for paper's experiments
    parser.add_argument('--goal_type', help='Specify the goal type', default="single stack order by color", type=str,
                        choices=sense.goal_types['block_world_sensor'])
    parser.add_argument('--num_objs', help='The exact number of objects to use in sensor, overrides min and max',
                        default=None, type=int)
    parser.add_argument('--num_demos', help='Specify the number of goal demos to give', default=100, type=int)
    parser.add_argument('--num_runs', help='Specify the number of runs for same experiment config', default=1, type=int)
    parser.add_argument('--num_goals', help='Specify the number of goals to generate', default=100, type=int)
    parser.add_argument('--factor_learner', help='Specify the factor learner', default='joint_frequency', type=str,
                        choices=learn.FACTOR_LEARNERS.keys())
    parser.add_argument('--use_consistency', help='Choose to use consistency prior', default=True, type=str2bool)
    parser.add_argument('--file', type=str, help='output csv file', default='out.csv')
    parser.add_argument('--experiment', type=str, help='Which experiment to run', default='single',
                        choices=['single', 'num_demos', 'paper'])

    # Extra useful arguments
    parser.add_argument('--min_num_objs', help='The min number of objects to use in sensor', default=3, type=int)
    parser.add_argument('--max_num_objs', help='The max number of objects to use in sensor', default=10, type=int)
    parser.add_argument('--percent_noise', help='Specify the percentage of noisy examples', default=0.0, type=float)
    parser.add_argument('--use_commonsense', help='Choose to use consistency prior', default=False, type=str2bool)
    parser.add_argument('--log_level', help='Set the logging level', default=logging.DEBUG, type=int,
                        choices=[logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL])
    parser.add_argument('-f', '--factors_to_learn', type=int, action='append',
                        help='A factor designated by number of objects in the factor multiple -f can be specified')

    args = parser.parse_args()
    if args.num_objs is not None:
        args.min_num_objs = args.num_objs
        args.max_num_objs = args.num_objs
    if args.factors_to_learn is None:
        args.factors_to_learn = [2]
    return args


def single_experiment(goal_type, num_objs, num_demos, num_goals,
                      sensor_name, learner_name, goal_generator_name, goal_evaluator_name,
                      factor_learner, factors_to_learn,
                      min_num_objs, max_num_objs,
                      use_consistency=False, use_commonsense=False,
                      percent_noise=0.0,
                      file_name='out.csv', goal_client='/get_goal'):
    logger.info('Experiment configured as:\n'
                '\tgoal_type: {}\n'
                '\tnum_objs: {}\n'
                '\tnum_demos: {}\n'
                '\tnum_goals: {}\n'
                '\tsensor_name: {}\n'
                '\tlearner_name: {}\n'
                '\tgoal_generator_name: {}\n'
                '\tgoal_evaluator_name: {}\n'
                '\tfactor_learner: {}\n'
                '\tfactors_to_learn: {}\n'
                '\tmin_num_objs: {}\n'
                '\tmax_num_objs: {}\n'
                '\tuse_consistency: {}\n'
                '\tuse_commonsense: {}\n'
                '\tpercent_noise: {}\n'
                '\tfile_name: {}\n'
                '\tgoal_client: {}'.format(goal_type,
                                           num_objs,
                                           num_demos,
                                           num_goals,
                                           sensor_name,
                                           learner_name,
                                           goal_generator_name,
                                           goal_evaluator_name,
                                           factor_learner,
                                           factors_to_learn,
                                           min_num_objs,
                                           max_num_objs,
                                           use_consistency,
                                           use_commonsense,
                                           percent_noise,
                                           file_name,
                                           goal_client))

    # Initialize and configure srp
    srp = srp_md.SrpMd(sensor=sensor_name, learner=learner_name, goal_generator=goal_generator_name,
                       goal_evaluator=goal_evaluator_name)
    srp.update_sensor_config(goal_type=goal_type, min_num_objs=min_num_objs, max_num_objs=max_num_objs)
    srp.update_learner_config(factor_learner=factor_learner, factors_to_learn=factors_to_learn)
    srp.update_goal_generator_config(use_consistency=use_consistency, use_commonsense=use_commonsense,
                                     goal_client=goal_client)

    # Initialize variables
    num_correct = 0
    total_noise = int(num_demos * percent_noise)
    num_noise = total_noise

    # Sense: generate needed demos
    while srp.get_num_demos() < num_demos:
        # Set demo type to be only goal, unless we get in the noise range
        demo_type = 'only_goal'
        if num_noise > 0:
            demo_type = 'only_not_goal'
        srp.update_sensor_config(demo_type=demo_type)
        # Try producing demo and see if any failure occurs
        try:
            srp.process_data()
            if demo_type == 'only_not_goal':
                num_noise -= 1
        except ValueError as e:
            logger.warn('Failed to get a demo: {}'.format(e))
    logger.info('Completed {} demos with {} bad examples'.format(srp.get_num_demos(), total_noise))

    # Learn: learn from demos
    srp.learn()
    logger.info('Learned')

    # Goal generate: generate goals from random observations
    srp.update_sensor_config(demo_type="only_goal", min_num_objs=6, max_num_objs=6)
    num_gen_goals = 0
    while num_gen_goals < num_goals:
        try:
            num_gen_goals += 1
            srp.generate_goal()
        except (ValueError, rospy.ServiceException) as e:
            logger.warn('Failed to generate goal trying again: ' + str(e))
            continue
        # Goal evaluate: evaluate goals generated
        try:
            if srp.evaluate_goal():
                num_correct += 1
        except ValueError as e:
            logger.warn('Failed to evaluate goal must be a bad goal...' + str(e))
    logger.info('Number of examples {}\n\t'
                'Number of bad examples {}\n\t'
                'Generated and evaluated {} goals with {}%% correct'.format(
                    num_demos, total_noise, num_gen_goals, 100.0 * num_correct / num_gen_goals))

    with file_lock:
        with open(file_name, mode='ab') as csv_file:
            # Setup csv file
            file_writer = csv.writer(csv_file)
            file_writer.writerow(
                [datetime.now(),
                 goal_type, num_objs, num_demos, num_goals, total_noise, num_correct,
                 factor_learner, factors_to_learn[0],
                 min_num_objs, max_num_objs,
                 use_consistency, use_commonsense])


def paper_experiment_generator(file_name):
    # Set what is constant
    kwargs = {'num_goals': 50, 'sensor_name': 'block_world_sensor', 'learner_name': 'factor_graph_learner',
              'goal_generator_name': 'factor_graph_goal_generator', 'goal_evaluator_name': 'adapt_goal_evaluator',
              'use_commonsense': False, 'file_name': file_name, 'percent_noise': 0.0, 'use_consistency': True}
    for goal_type in ["single stack order by color"]:  # sense.goal_types['block_world_sensor'][:3]:
        kwargs['goal_type'] = goal_type
        for num_objs in [3, 4]:
            factors_to_learn = [[2]]
            min_num_objs = 3
            max_num_objs = 3
            if isinstance(num_objs, list):
                min_num_objs = num_objs[0]
                max_num_objs = num_objs[1]
            else:
                # if num_objs < 5:  # Don't learn joint factors greater than 4 because it takes to long
                #     factors_to_learn.append([num_objs])
                min_num_objs = num_objs
                max_num_objs = num_objs
            kwargs['num_objs'] = num_objs
            kwargs['min_num_objs'] = min_num_objs
            kwargs['max_num_objs'] = max_num_objs
            for factor_to_learn in factors_to_learn:
                kwargs['factors_to_learn'] = factor_to_learn
                for factor_learner in ['decision_tree', 'svm']:  # learn.FACTOR_LEARNERS.keys():
                    kwargs['factor_learner'] = factor_learner
                    for num_demos in list(xrange(1, 11)):
                        kwargs['num_demos'] = num_demos
                        for i in xrange(5):
                            yield dict(kwargs)


class PaperThread(multiprocessing.Process):
    # Tracking variables
    num_experiments = len(list(paper_experiment_generator(None)))
    num_completed = multiprocessing.Value('i', 0)
    start_time = None
    average_runtime = multiprocessing.Value('d', 0)
    NUM_THREADS = 32

    def __init__(self, name, experiment_queue, lock):
        multiprocessing.Process.__init__(self)
        self._name = name
        self._experiment_queue = experiment_queue
        self._lock = lock
        self._get_goal_client = '/get_goal_{}'.format(self._name)

    def run(self):
        kwargs = None
        gen_empty = False
        # Keep working until there is nothing left to do
        while not gen_empty:
            # Get the next job
            try:
                kwargs = self._experiment_queue.get_nowait()
            except Queue.Empty:
                # If there are no jobs left finish
                gen_empty = True
                continue
            # Set the goal client and run the experiment
            kwargs['goal_client'] = self._get_goal_client
            cur_start = time.time()
            single_experiment(**kwargs)
            cur_end = time.time()
            cur_diff = cur_end - cur_start

            # Update and print statistics
            with self._lock:
                PaperThread.num_completed.value += 1
                PaperThread.average_runtime.value = ((cur_diff + (PaperThread.num_completed.value - 1) *
                                                     PaperThread.average_runtime.value) /
                                                     PaperThread.num_completed.value)
                elapsed = time.time() - PaperThread.start_time
                expected_remaining = (PaperThread.average_runtime.value * (
                    PaperThread.num_experiments - PaperThread.num_completed.value) / PaperThread.NUM_THREADS)
                print ('---------------------------\n'
                       'Completed {} of {} ({}%)\nCurrent time {}\nAverage time {}\nElapsed time {}\n'
                       'Expected remaining time {}'
                       .format(PaperThread.num_completed.value, PaperThread.num_experiments,
                               float(PaperThread.num_completed.value) / PaperThread.num_experiments, cur_diff,
                               PaperThread.average_runtime.value, elapsed, expected_remaining))


def paper_experiment(file_name):
    experiment_queue = multiprocessing.Queue()
    for kwargs in paper_experiment_generator(file_name):
        experiment_queue.put(kwargs)
    lock = multiprocessing.Lock()
    thread_pool = []
    PaperThread.start_time = time.time()
    for i in xrange(PaperThread.NUM_THREADS):
        thread = PaperThread(i + 1, experiment_queue, lock)
        thread.start()
        thread_pool.append(thread)

    for thread in thread_pool:
        thread.join()


def main():
    # Get arguments
    args = parse_args()
    logger.setLevel(args.log_level)
    logger.info('Running experiment with these args: {}'.format(args))

    # Setup ros
    rospy.init_node('run_experiment', anonymous=True)

    if args.experiment == 'single':
        single_experiment(args.goal_type, args.num_objs, args.num_demos, args.num_goals,
                          "block_world_sensor", "factor_graph_learner",
                          "factor_graph_goal_generator", "adapt_goal_evaluator",
                          args.factor_learner, args.factors_to_learn,
                          args.min_num_objs, args.max_num_objs,
                          args.use_consistency, args.use_commonsense,
                          args.percent_noise,
                          args.file)
    elif args.experiment == 'num_demos':
        for num_demos in xrange(1, 26):
            single_experiment(args.goal_type, args.num_objs, args.num_demos, args.num_goals,
                              "block_world_sensor", "factor_graph_learner",
                              "factor_graph_goal_generator", "adapt_goal_evaluator",
                              args.factor_learner, args.factors_to_learn,
                              args.min_num_objs, args.max_num_objs,
                              args.use_consistency, args.use_commonsense,
                              args.percent_noise,
                              args.file)
    elif args.experiment == 'paper':
        paper_experiment(args.file)


if __name__ == '__main__':
    logger.info('Experiment starting up... #BOLD')
    sys.argv = rospy.myargv()
    try:
        main()
    finally:
        logger.info('Experiment stopping... #BOLD')
