#!/usr/bin/env python
from __future__ import print_function
from builtins import range
from builtins import input
# In project imports
import srp_md
from srp_md import learn, sense, srp_md_log, utils

# Ros and Python imports
import rospy
import logging
import random
import pickle
import os
import argparse
import itertools
# import sys
# import random
import csv
# from datetime import datetime
import time
import yaml
import multiprocessing
import Queue

# Global locks
io_lock = multiprocessing.Lock()

# Define file path
script_path = os.path.dirname(os.path.realpath(__file__))
data_folder = os.path.realpath(script_path + '/../../data')
demo_folder = os.path.realpath(script_path + '/../../data/demos')

# Get a logger
logger = logging.getLogger('srp_md')
logger.setLevel(logging.DEBUG)

# Initialize variables
# OBJECTS = ["cracker", "gelatin", "meat", "mustard", "soup", "sugar", "bleach"]
OBJECTS = ["cracker", "meat", "mustard", "soup", "sugar"]
RELATIONS = ["disjoint", "proximity", "on", "support"]
FEATURES = yaml.load(open(os.path.realpath(script_path + '/../config/feature_space.yaml'), 'r'))

# Objects used in experiments
training_classes = ["cracker", "meat", "mustard", "soup", "sugar", "gelatin", "apple"]
all_classes = FEATURES.keys()
all_classes.remove('table')
test_classes = all_classes[:]
size_dict = {"s_small": 1, "s_medium": 2, "s_large": 3}

# Grocery experiment list
grocery_experiment_demo_objs = [
    # ["cracker", "cracker", "sugar", "soup", "soup", "meat"],
    # ["cracker", "sugar", "sugar", "meat", "meat", "meat"],
    # ["cracker", "sugar", "soup", "soup", "soup", "mustard"],
    # ["cracker", "cracker", "sugar", "sugar", "mustard", "mustard", "soup"],
    # ["cracker", "sugar", "sugar", "sugar", "mustard", "meat", "meat"],
    # ["cracker", "cracker", "sugar", "soup", "soup", "meat", "meat"],
    # ["cracker", "sugar", "meat", "meat", "meat", "soup", "soup"],
    # ["cracker", "sugar", "sugar", "soup", "meat", "soup"],
    # ["cracker", "sugar", "soup", "soup", "meat", "meat"],
    # ["cracker", "cracker", "sugar", "mustard", "mustard", "mustard", "mustard"],
    # ["cracker", "cracker", "sugar", "meat", "meat", "soup"],
    # ["cracker", "cracker", "cracker", "sugar", "mustard", "mustard", "mustard"],
    # ["cracker", "sugar", "sugar", "sugar", "meat", "meat", "soup"],
    # ["cracker", "cracker", "sugar", "meat", "meat", "meat"],
    # ["sugar", "sugar", "sugar", "soup", "soup", "soup"],
    # ["cracker", "cracker", "cracker", "soup", "soup", "soup", "soup"],
    # ["cracker", "cracker", "meat", "meat", "meat", "soup", "mustard"],
    # ["cracker", "sugar", "sugar", "soup", "meat", "meat", "mustard"],
    # ["cracker", "sugar", "soup", "soup", "meat", "mustard", "mustard"],
    ["cracker", "sugar", "sugar", "soup", "soup", "mustard"]
]


def generate_demo_scenes(demo_num, demo_objs_nums, noise_num, obj_list=None):
    """
    Hardcode Examples
    """
    scene_graphs = []

    # For number of demos needed, do:
    for i in range(demo_num):

        # Pick objects randomly, based on number of demos (which is also chosen randomly from recommended list)
        objs = [srp_md.Object(name="table", id_num=0, uuid=0, assignment=FEATURES["table"])]
        uuid = 1
        for j in range(random.choice(demo_objs_nums)):
            name = random.choice(OBJECTS)
            if obj_list is not None:
                name = obj_list[i][j]
            objs.append(srp_md.Object(name=name + "_" + str(uuid), id_num=uuid, uuid=uuid, assignment=FEATURES[name]))
            uuid += 1

        scene_graph = srp_md.SceneGraph(objs)
        # print(scene_graph.get_obj_names())

        # Update all relations based on general grocery goal
        print("\nObjects List: ", scene_graph.get_obj_names(), "\n")
        for relation in scene_graph.relations:
            user_input = None

            # Make the user give inputs
            print("For ", relation.obj1, " and ", relation.obj2)
            print("Relation list: ", RELATIONS)
            user_input = input("Specify relation for relations in the list by their index: \n")
            while int(user_input) not in range(len(RELATIONS)):
                user_input = input("Wrong value! Choose again... \n")
            relation.value = RELATIONS[int(user_input)]
            print("You chose: ", relation.value, "\n")

        # Add noise to the relation
        if i < noise_num:
            relation = random.choice(scene_graph.relations)
            relation.value = RELATIONS[random.randint(0, len(RELATIONS) - 1)]

        scene_graphs.append(scene_graph)

    return scene_graphs


def generate_demo_scenes_from_list(objs_list):
    scene_graphs = []
    for i, objs in enumerate(objs_list):
        print('New scene graph with {}'.format(objs))
        sg_objs = [srp_md.Object(name='{}_{}'.format(obj, uuid),
                   id_num=uuid, uuid=uuid, assignment=FEATURES[obj]) for uuid, obj in enumerate(objs)]
        sg_objs.append(
            srp_md.Object(name='table', id_num=len(sg_objs), uuid=len(sg_objs), assignment=FEATURES["table"]))
        scene_graph = srp_md.SceneGraph(sg_objs)
        index = 0
        while index < len(scene_graph.relations):
            while True:
                try:
                    rel = scene_graph.relations[index]
                    rel.value = RELATIONS[int(input(
                        'X(    {},    {}    )\n  Choices: {} (>={}: go back):\n'.format(
                         rel.obj1, rel.obj2, list(enumerate(RELATIONS)), len(RELATIONS))))]
                    index += 1
                    break
                except IndexError:
                    print('Go back to previous relation\n')
                    index = max(index - 1, 0)
                except ValueError:
                    print('Input an integer')
            print('{}({}, {})\n'.format(rel.value, rel.obj1, rel.obj2))
        scene_graphs.append(scene_graph)
        save_graphs(scene_graphs, 'save_state.pickle', 'save_state', i, '{}/graphs'.format(data_folder))
        print('Saved scene with {}'.format(objs))

    return scene_graphs


def generate_random_demo_scene(num_objs, objs_list):
    # Add the table
    table = srp_md.Object(name='table', id_num=0, uuid=0, assignment=FEATURES["table"])
    objs = [table]
    # Make num_objs random objs
    for uuid in range(1, num_objs+1):
        # Select a random object from objs_list
        new_class = random.choice(objs_list)
        objs.append(srp_md.Object(
            name='{}_{}'.format(new_class, uuid), id_num=uuid, uuid=uuid, assignment=FEATURES[new_class]))
    # Construct scene graph
    sg = srp_md.SceneGraph(objs)
    # Initialise all relations to disjoint
    for rel in sg.relations:
        rel.value = 'disjoint'
    # Assign the relations
    # Put everything on the table
    for rel in sg.relations:
        if rel.obj1 == table:
            rel.value = 'support'
        elif rel.obj2 == table:
            rel.value = 'on'
    # Stack the boxes by size
    boxes = [obj for obj in sg.objs if obj.assignment["shape"] == "box"]
    # Sort from smallest to largest (so top to bottom)
    boxes.sort(key=lambda obj: size_dict[obj.assignment["size"]])
    for i, box1 in enumerate(boxes):
        for box2 in boxes[i+1:]:
            rel = sg.get_rel_by_objs(box1, box2)
            if box1 == rel.obj1:
                rel.value = 'on'
            else:
                rel.value = 'support'
    # Put cans next to bottom box
    try:
        bot_box = boxes[-1]
        for can in filter(lambda obj: obj.assignment["shape"] == "cylinder", sg.objs):
            rel = sg.get_rel_by_objs(bot_box, can)
            rel.value = 'proximity'
    except IndexError:
        pass
    # Make sure complex objects are disjoint
    for complex_obj in filter(lambda obj: obj.assignment["shape"] == "complex", sg.objs):
        for obj in filter(lambda obj: not (obj == table or obj == complex_obj), sg.objs):
            rel = sg.get_rel_by_objs(complex_obj, obj)
            if obj.assignment["shape"] == 'complex':
                rel.value = random.choice(['proximity', 'disjoint'])
            # else:
            #     print('{} - {} - {}'.format(complex_obj.name, obj.name, rel.value))
    return sg


# TODO(Kevin): Use the new random scene graph generator from scene_graph.py
def generate_init_scenes(num_test_scenes, num_objs, obj_list=None):
    """
    Hardcode Examples
    """
    if obj_list is None:
        obj_list = OBJECTS

    scene_graphs = []
    num_novel = 0

    # For number of demos needed, do:
    for i in range(num_test_scenes):

        while num_novel == 0:
            # Pick objects randomly, based on number of demos (which is also chosen randomly from recommended list)
            objs = [srp_md.Object(name="table", id_num=0, uuid=0, assignment=FEATURES["table"])]
            uuid = 1
            for _ in range(random.choice(num_objs)):
                name = random.choice(obj_list)
                if name in test_classes:
                    num_novel += 1
                objs.append(srp_md.Object(name=name + "_" + str(uuid), id_num=uuid, uuid=uuid, assignment=FEATURES[name]))
                uuid += 1

        scene_graph = srp_md.SceneGraph(objs)

        # print "\nObjects List: ", scene_graph.get_obj_names(), "\n"

        # Make all relations disjoint
        for relation in scene_graph.relations:
            relation.value = 'disjoint'
            if relation.obj1.name == 'table':
                relation.value = 'support'

        scene_graphs.append(scene_graph)

    return scene_graphs, num_novel


def save_graphs(graphs, pickle_name, file_prefix, current_trial, dirname):
    # pickle_file = os.path.join(dirname, pickle_name)
    # pickle.dump(graphs, open(pickle_file, 'wb'))
    for i, graph in enumerate(graphs):
        if graph is None:
            continue
        graph.to_all(os.path.join(dirname, "{}_{}".format(file_prefix, i + current_trial)), draw_disjoint=False,
                     flip_relations=True)


def save_all(demo_graphs, test_graphs, generated_graphs, plans, current_trial, dirname):
    if demo_graphs is not None:
        save_graphs(demo_graphs, 'data.pickle', 'demo', current_trial, dirname)
    save_graphs(test_graphs, 'test.pickle', 'test', current_trial, dirname)
    save_graphs(generated_graphs, 'generated.pickle', 'generated', current_trial, dirname)
    if plans is not None:
        save_plans(plans, current_trial, dirname)


def save_plans(plans, current_trial, dirname):
    for i, plan in enumerate(plans):
        with open(dirname + '/plan_{}.soln'.format(i + current_trial), 'w+') as file:
            if plan is not None:
                for action in plan:
                    file.write(' '.join(action) + '\n')


def load_demos(dirname):
    file_names = [os.path.join(dirname, file) for file in os.listdir(dirname)
                  if os.path.isfile(os.path.join(dirname, file)) and os.path.splitext(file)[-1] == '.sg']
    # Sort by number, note this expects the name to follow this pattern '<name>_#.sg'
    file_names.sort(key=lambda name: int(name[name.rfind('_')+1:name.rfind('.sg')]))
    demo_graphs = [srp_md.SceneGraph.from_file(file_name) for file_name in file_names]
    return demo_graphs


def evaluate_goal(scene):
    # Ensure a scene was generated
    if scene is None:
        return (False, 'failed to generate any goal')

    # Ensure everything is on the table
    table = [obj for obj in scene.objs if obj.name.find('table') != -1][0]
    for obj in filter(lambda obj: not obj == table, scene.objs):
        rel = scene.get_rel_by_objs(obj, table)
        if rel.obj1 == table:
            if rel.value != 'support':
                return (False, 'table does not support an object')
        else:
            if rel.value != 'on':
                return (False, 'an object is not on a table')

    # Ensure all boxes are stacked by size
    boxes = [obj for obj in scene.objs if obj.assignment["shape"] == "box"]
    for objs in itertools.combinations(boxes, 2):
        rel = scene.get_rel_by_objs(objs[0], objs[1])
        # Both objects the same size
        if objs[0].assignment["size"] == objs[1].assignment["size"]:
            if rel.value != 'support' and rel.value != 'on':
                return (False, 'boxes not stacked')
        # Different size
        else:
            if size_dict[rel.obj1.assignment["size"]] > size_dict[rel.obj2.assignment["size"]]:
                if rel.value != 'support':
                    return (False, 'larger box must support smaller one')
            else:
                if rel.value != 'on':
                    return (False, 'smaller box must be on bigger one')

    # Ensure that the bottom box is next to all cans
    # Find the bottom box
    bot_box = None
    for box in boxes:
        num_on = 0
        for obj in filter(lambda obj: not obj == box, scene.objs):
            rel = scene.get_rel_by_objs(box, obj)
            if rel.obj1 == box:
                if rel.value == 'on':
                    num_on += 1
            elif rel.value == 'support':
                num_on += 1
            if num_on > 1:
                break
        if num_on == 1:
            bot_box = box
            break
    # Ensure all cans next to bot_box
    if bot_box is not None:
        for obj in filter(lambda obj: obj.assignment["shape"] == "cylinder",
                          scene.objs):
            rel = scene.get_rel_by_objs(obj, bot_box)
            if rel.value != 'proximity':
                return (False, 'cans not proximity to bottom box')

    # Ensure complex objects are grouped together but disjoint with all but the table
    for complex_obj in filter(lambda obj: obj.assignment["shape"] == "complex", scene.objs):
        for other_obj in filter(lambda obj: not (obj == table or obj == complex_obj), scene.objs):
            rel = scene.get_rel_by_objs(complex_obj, other_obj)
            # Proximity or disjoint to other complex object
            if other_obj.assignment["shape"] == "complex":
                if rel.value != 'proximity' and rel.value != 'disjoint':
                    return (False, 'complex object not proximity or disjoint with other complex object')
            elif rel.value != 'disjoint':
                return (False, 'complex object not disjoint with non-complex object')

    return (True, 'success')


def powerset(iterable):
    s = list(iterable)
    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s) + 1))


def random_combinations(iterable, r, num_combos):
    """Random selection from itertools.combinations(iterable, r)"""
    pool = tuple(iterable)
    n = len(pool)
    for _ in range(num_combos):
        yield tuple(pool[index] for index in sorted(random.sample(range(n), r)))


def random_powerset(iterable, num_to_sample):
    """!
    @brief      Randomly sample from the powerset in order of set size

    @param      iterable       The iterable
    @param      num_to_sample  The number to sample from each set size,
                               if num_to_sample > len(iterable)! / (r! (n - r)!) then sample all combinations of size r

    @return     Generator of the randomly selected elements of the powerset in order of set size
    """
    s = list(iterable)
    n = len(s)
    chain = itertools.chain()
    for r in range(n + 1):
        if utils.ncr(n, r) <= num_to_sample:
            chain = itertools.chain(chain, itertools.combinations(s, r))
        else:
            chain = itertools.chain(chain, random_combinations(s, r, num_to_sample))
    return chain


def len_random_powerset(len_iterable, num_to_sample):
    size = 0
    for r in range(len_iterable + 1):
        ncr = utils.ncr(len_iterable, r)
        if ncr <= num_to_sample:
            size += ncr
        else:
            size += num_to_sample
    return size


def secs_to_str(secs):
    secs = int(secs)
    weeks = secs // 604800
    secs = secs % 604800
    days = secs // 86400
    secs = secs % 86400
    hours = secs // 3600
    secs = secs % 3600
    miniutes = secs // 60
    secs = secs % 60
    return '{}w {}d {}h {}m {}s'.format(weeks, days, hours, miniutes, secs)


def parse_args():
    """
    Parse input arguments
    """
    parser = argparse.ArgumentParser(description='Run an simulated experiment')

    # Main arguments, used for paper's experiments
    parser.add_argument('--factor_learner', help='Specify the factor learner', default='decision_tree', type=str,
                        choices=learn.FACTOR_LEARNERS.keys())
    parser.add_argument('--use_consistency', help='Choose to use consistency prior', default=True, type=srp_md.str2bool)
    parser.add_argument('--use_no_float', help='Choose to use no float prior', default=False, type=srp_md.str2bool)
    parser.add_argument('--use_cardinality', help='Choose to use learned cardinality', default=True,
                        type=srp_md.str2bool)
    parser.add_argument('--demo_graphs_dir', type=str, help='Folder with all .sg files'
                        ' if not provided then demos will be randomly generated')
    parser.add_argument('--test_graphs_dir', type=str, help='Folder of test scenes as .sg files'
                        ' if not provided then random initial scenes will be generated')
    parser.add_argument('--num_test_scenes', type=int, default=10, help='Number of test scenes to use for every set'
                        ' of demonstrations')
    parser.add_argument('--num_samples', type=int, default=20, help='Number of random samples to to take from each '
                        'possible cardinality of demonstrations')
    parser.add_argument('--max_num_demos', type=int, default=20, help='Max number of demonstrations to learn from')
    parser.add_argument('--min_num_demos', type=int, default=1, help='Min number of demonstrations to learn from')
    parser.add_argument('--max_demo_size', type=int, default=10, help='Maximum number of objects in a randomly '
                        'generated demo scene')
    parser.add_argument('--min_demo_size', type=int, default=3, help='Minimum number of objects in a randomly '
                        'generated demo scene')
    parser.add_argument('--max_test_size', type=int, default=4, help='Maximum number of objects in test scene')
    parser.add_argument('--min_test_size', type=int, default=3, help='Minimum number of objects in test scene')
    parser.add_argument('--use_novel_classes', type=srp_md.str2bool, default=False, help='Use novel objects')
    parser.add_argument('--rand_train_set', type=srp_md.str2bool, default=False, help='Randomize the training set')
    parser.add_argument('--num_train_sets', type=int, default=20, help='When using rand_train_set use this '
                        'many random sets')
    parser.add_argument('--plan', type=srp_md.str2bool, default=True, help='True plan, false don\'t plan')
    parser.add_argument('--num_threads', type=int, default=4, help='Number of threads to use')
    parser.add_argument('output_dir', type=str,
                        help='To write the demo, test, and generated .sg files and results.csv',
                        default='{}/graphs'.format(data_folder))

    # Extra useful arguments
    parser.add_argument('--log_level', help='Set the logging level', default=logging.DEBUG, type=int,
                        choices=[logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL])

    args, others = parser.parse_known_args()

    if not args.rand_train_set:
        args.num_train_sets = 1

    # Handle input file dirs
    for path in [args.demo_graphs_dir, args.test_graphs_dir]:
        if path is not None:
            if not os.path.isdir(path):
                raise(IOError('{} not a valid path'.format(path)))
    # Handle output file dirs
    if args.output_dir is not None:
        if not os.path.isdir(args.output_dir):
            os.mkdir(args.output_dir)

    return args


def num_trials_single(min_test_size, max_test_size, num_test_scenes, **kwargs):
    return (max_test_size - min_test_size + 1) * num_test_scenes


def num_trials(**kwargs):
    return None  # TODO


def run_one(factor_learner, use_consistency, use_no_float, use_cardinality, demo_graphs, num_test_scenes,
            max_test_size, min_test_size, use_novel_classes, training_classes, test_classes, trial_min_index,
            trial_start_index, goal_client, num_demos, min_demo_size, max_demo_size, plan, output_dir):
    # Name trials
    trials_name = 'trials_{}-{}'.format(
        trial_min_index,
        trial_min_index + num_trials_single(min_test_size, max_test_size, num_test_scenes) - 1)

    # Log experment parameters
    with io_lock:
        logger.info('Run trials {} with: {}'.format(trials_name, locals()))

    # Make a timer
    timer = srp_md.GlobalTimer()
    timer.start(trials_name)

    # Setup SRP_MD object
    srp = srp_md.SrpMd(feature_space=FEATURES,
                       sensor="dope_sensor",
                       learner="factor_graph_learner",
                       goal_generator="factor_graph_goal_generator")
    srp.update_learner_config(factor_learner=factor_learner)
    srp.update_goal_generator_config(use_consistency=use_consistency, use_no_float=use_no_float,
                                     use_cardinality=use_cardinality, goal_client=goal_client)

    # Use provided or generate demos
    timer.start(trials_name + '_demos')
    if demo_graphs is None:
        # Generate
        demo_graphs = []
        for _ in range(num_demos):
            num_objs = random.randint(min_demo_size, max_demo_size)
            demo_graphs.append(generate_random_demo_scene(num_objs, training_classes))
    srp.set_demo_graphs(demo_graphs)
    timer.stop(trials_name + '_demos')

    # Learn
    timer.start(trials_name + '_learn')
    srp.learn()
    timer.stop(trials_name + '_learn')

    # Perform tests
    for i, num_test_objs in enumerate(range(min_test_size, max_test_size + 1)):
        for j in range(num_test_scenes):
            # Generate trial number and name
            trial_num = trial_min_index + i * num_test_scenes + j
            trial_name = 'trial_{}'.format(trial_num)
            if trial_num < trial_start_index:
                continue

            # Start trial timer
            timer.start(trial_name)

            # Generate test scene
            timer.start(trial_name + '_test')

            def gen_test():
                obj_classes = training_classes[:]
                if use_novel_classes:
                    obj_classes = test_classes[:]
                test_graph = srp_md.SceneGraph.random_sg(num_test_objs, obj_classes, FEATURES, 'disjoint')
                num_novel = len(filter(lambda obj: obj.assignment['class'] != 'table' and
                                       obj.assignment['class'] not in training_classes, test_graph.objs))
                return test_graph, num_novel

            test_graph, num_novel = gen_test()
            while use_novel_classes and num_novel == 0:
                test_graph, num_novel = gen_test()
            srp.set_init_graphs([test_graph])
            timer.stop(trial_name + '_test')

            # Generate the goal
            timer.start(trial_name + '_goal')
            srp.generate_goal()
            timer.stop(trial_name + '_goal')

            # Plan
            timer.start(trial_name + '_plan')
            plans = None
            if plan:
                plans = srp.plan()
            timer.stop(trial_name + '_plan')

            # End trial timer
            timer.stop(trial_name)

            # Evaluate
            result, reason = evaluate_goal(srp._goal_instances[0])

            # Write results
            with io_lock:
                # To cli
                logger.info('{} goal generation {} {}'.format(trial_name, 'succeded' if result else 'failed',
                                                              'because ' + reason if not result else ''))

                # To CSV
                with open(output_dir + '/results.csv', 'a+') as global_results_file:
                    global_results_writer = csv.writer(global_results_file)
                    global_results_writer.writerow([trial_num, len(demo_graphs), result, reason,
                                                    test_graph.num_objs(), num_novel,
                                                    len(training_classes), '-'.join(sorted(training_classes)),
                                                    len(test_classes), '-'.join(sorted(test_classes)),
                                                    timer.diff_times[trials_name + '_demos'],
                                                    timer.diff_times[trials_name + '_learn'],
                                                    timer.diff_times[trial_name],
                                                    timer.diff_times[trial_name + '_test'],
                                                    timer.diff_times[trial_name + '_goal'],
                                                    timer.diff_times['generate_goal'],
                                                    timer.diff_times['generate_goal_request'],
                                                    timer.diff_times['generate_goal_response'],
                                                    timer.diff_times[trial_name + '_plan']])

                # # To .sg and soln files
                # save_all(None, [test_graph], srp._goal_instances, plans, trial_num, output_dir)

                # global_index += len(srp._goal_instances)
                # avg_time = (diff + (global_index - last_trial) * avg_time) / (global_index - last_trial + 1)
                # print('----------------------')
                # logger.info('avg_time: {}'.format(avg_time))
                # logger.info('Trial: {} ({} remaining)'.format(global_index, num_trials - global_index))
                # logger.info('Estimated time remaining: {}'.format(secs_to_str((num_trials - global_index) * avg_time)))
                # logger.info('Percent completed: {}%'.format(100.0 * (global_index) / num_trials))
                # print('----------------------')
                #
    timer.stop(trials_name)


class ExperimentThread(multiprocessing.Process):
    def __init__(self, params_queue, goal_client):
        super(ExperimentThread, self).__init__()
        self._params_queue = params_queue
        self._goal_client = goal_client

    def run(self):
        # Prepare vars
        kwargs = None
        more_experiments = True
        # Loop until all experiments done
        while more_experiments:
            # Get the next experiment parameters
            try:
                kwargs = self._params_queue.get_nowait()
            except Queue.Empty:
                more_experiments = False
                continue

            # Update kwargs
            kwargs['goal_client'] = self._goal_client
            run_one(**kwargs)


def make_rand_training_set():
    return random.sample(all_classes, random.randint(4, len(all_classes)))


def experiment_generator(args, demo_graphs, completed):
    # Default kwargs
    training_set = training_classes[:]
    test_set = test_classes[:]
    kwargs = {
        'factor_learner': args.factor_learner,
        'use_consistency': args.use_consistency,
        'use_no_float': args.use_no_float,
        'use_cardinality': args.use_cardinality,
        'demo_graphs': demo_graphs,
        'num_test_scenes': args.num_test_scenes,
        'max_test_size': args.max_test_size,
        'min_test_size': args.min_test_size,
        'use_novel_classes': args.use_novel_classes,
        'training_classes': training_set,
        'test_classes': test_set,
        'trial_min_index': 0,
        'trial_start_index': 0,
        'num_demos': 20,
        'min_demo_size': args.min_demo_size,
        'max_demo_size': args.max_demo_size,
        'plan': args.plan,
        'output_dir': args.output_dir
    }

    # Get number of trials in a single run
    num_in_single = num_trials_single(**args.__dict__)
    demo_index_offset = (args.max_num_demos - args.min_num_demos + 1)
    # Handle random training sets
    for training_set_index in range(args.num_train_sets):
        if args.rand_train_set:
            training_set = make_rand_training_set()
            # Ensure novel objects exist if needed
            while args.use_novel_classes and all([item not in training_set for item in test_set]):
                training_set = make_rand_training_set()
        kwargs['training_classes'] = training_set
        for demo_index, num_demos in enumerate(range(args.min_num_demos, args.max_num_demos + 1)):
            # Set number of demos to use
            kwargs['num_demos'] = num_demos
            for sample_index in range(args.num_samples):
                # Determine trial numbers
                min_trial = (training_set_index * (demo_index_offset * args.num_samples * num_in_single) +
                             demo_index * (args.num_samples * num_in_single) +
                             sample_index * num_in_single)
                max_trial = min_trial + num_in_single - 1
                # Reset trial start
                kwargs['trial_min_index'] = min_trial
                kwargs['trial_start_index'] = min_trial
                if min_trial not in completed:
                    # Hasn't been started yet
                    yield dict(kwargs)
                elif max_trial not in completed:
                    # Stoped in the middle find where to start
                    for trial_index in range(min_trial, max_trial + 1):
                        if trial_index not in completed:
                            kwargs['trial_start_index'] = trial_index
                            yield dict(kwargs)
                            break


def main():
    args = parse_args()
    logger.setLevel(args.log_level)
    logger.info('Running experiment with these args: {}'.format(args))

    # Setup ROS
    rospy.init_node('simulate_experiment', anonymous=True)
    logger.info('Started the simulate_experiment node...')
    # init_folder = os.path.realpath(script_path + '/../../data/inits')

    timer = srp_md.GlobalTimer()
    timer.start('experiment')

    # timer.start('load_demos')
    demo_graphs = None
    if args.demo_graphs_dir is not None:
        demo_graphs = (
            load_demos(args.demo_graphs_dir) +
            [generate_random_demo_scene((num_objs % 10) + 2,
             filter(lambda x: x != 'table', training_classes)) for num_objs in range(100)])
    # else:
    #     # Simulate goal scenegraphs
    #     # demo_num, demo_objs_nums, noise_num = 20, [6], 0
    #     demo_graphs = generate_demo_scenes_from_list(grocery_experiment_demo_objs)
    #     # demo_graphs = generate_demo_scenes(demo_num, demo_objs_nums, noise_num)
    #     # demo_graphs = generate_demo_scenes(demo_num, demo_objs_nums, noise_num,
    #     #                                    [["cracker", "gelatin", "meat", "soup", "sugar"],
    #     #                                     ["cracker", "gelatin", "gelatin", "mustard", "bleach"]])
    # save_graphs(demo_graphs, 'data.pickle', 'demo', 0, args.output_dir)
    # print([evaluate_goal(sg) for sg in demo_graphs])
    # timer.stop('load_demos')
    # logger.info('Generated {} demo graphs with {} noises'.format(len(demo_graphs), 0))

    # Setup SRP_MD object
    # srp = srp_md.SrpMd(feature_space=FEATURES,
    #                    sensor="dope_sensor",
    #                    learner="factor_graph_learner",
    #                    goal_generator="factor_graph_goal_generator")
    # srp.update_learner_config(factor_learner=args.factor_learner)
    # srp.update_goal_generator_config(use_consistency=args.use_consistency, use_no_float=args.use_no_float,
    #                                  use_cardinality=args.use_cardinality)

    # Pickup where you left off
    completed = []
    with open(args.output_dir + '/results.csv', 'r') as results_file:
        csv_reader = csv.reader(results_file)
        for row in csv_reader:
            completed.append(int(row[0]))
    logger.info('Previously completed {} trials'.format(len(completed)))

    # Put all trials into queue
    params_queue = multiprocessing.Queue()
    for kwargs in experiment_generator(args, demo_graphs, completed):
        params_queue.put(kwargs)

    # Start worker threads
    thread_pool = []
    for thread_index in range(args.num_threads):
        thread = ExperimentThread(params_queue, '/get_goal{}'.format(thread_index))
        thread.start()
        thread_pool.append(thread)
    for thread in thread_pool:
        thread.join()

    # run_one(
    #     factor_learner=args.factor_learner,
    #     use_consistency=args.use_consistency,
    #     use_no_float=args.use_no_float,
    #     use_cardinality=args.use_cardinality,
    #     demo_graphs=demo_graphs,
    #     num_test_scenes=args.num_test_scenes,
    #     max_test_size=args.max_test_size,
    #     min_test_size=args.min_test_size,
    #     use_novel_classes=args.use_novel_classes,
    #     training_classes=training_classes,
    #     test_classes=test_classes,
    #     trial_start_index=0,
    #     goal_client='/get_goal',
    #     num_demos=20,
    #     min_demo_size=args.min_demo_size,
    #     max_demo_size=args.max_demo_size,
    #     plan=args.plan,
    #     output_dir=args.output_dir)
    # avg_time = 0
    # num_trials = (args.max_test_size - args.min_test_size + 1) * args.num_test_scenes
    # srp.set_scenes(demo_graphs, None)
    # timer.start('learn')
    # srp.learn()
    # timer.stop('learn')
    # logger.info('Learn')
    # for trial_set, num_objs in enumerate(range(args.min_test_size, args.max_test_size + 1)):
    #     for test_scene in range(args.num_test_scenes):
    #         current_trial = trial_set * args.num_test_scenes + test_scene
    #         if current_trial <= last_trial:
    #             continue

    #         # Trial timer
    #         trial_name = 'trial_{}'.format(global_index)
    #         start_time = time.time()
    #         timer.start(trial_name)

    #         # Simulate initial scenegraphs
    #         init_scene_name = 'init_scene_{}'.format(global_index)
    #         timer.start(init_scene_name)
    #         test_graphs, num_novel = generate_init_scenes(1, [num_objs], all_classes)
    #         timer.stop(init_scene_name)
    #         logger.info('Generated {} initial scenes'.format(len(test_graphs)))

    #         srp.set_scenes(demo_graphs, test_graphs)
    #         logger.info('Initialized SrpMd object with {} demos'.format(len(demo_graphs)))

    #         # Generate goals from learned factors
    #         # try rospy.service.ServiceException
    #         goal_name = 'goal_{}'.format(global_index)
    #         timer.start(goal_name)
    #         srp.generate_goal()
    #         timer.stop(goal_name)
    #         logger.info('Generated goals')

    #         plan_name = 'plan_{}'.format(global_index)
    #         timer.start(plan_name)
    #         plans = srp.plan()
    #         # plans = [None]
    #         timer.stop(plan_name)

    #         # Timing info
    #         timer.stop(trial_name)
    #         diff = time.time() - start_time

    #         # Generate results.csv
    #         with open(args.output_dir + '/results.csv', 'a+') as global_results_file:
    #             global_results_writer = csv.writer(global_results_file)
    #             for index, (goal, test_graph) in enumerate(zip(srp._goal_instances, test_graphs)):
    #                 result, reason = evaluate_goal(goal)
    #                 logger.info('Generated goal {} {} {}'.format(index,
    #                                                              'succeded' if result else 'failed',
    #                                                              'because ' + reason if not result else ''))
    #                 global_results_writer.writerow([index + global_index, len(demo_graphs), result, reason,
    #                                                 test_graph.num_objs(), num_novel, diff, timer.diff_times[trial_name],
    #                                                 timer.diff_times[init_scene_name], timer.diff_times[goal_name],
    #                                                 timer.diff_times['generate_goal'],
    #                                                 timer.diff_times['generate_goal_request'],
    #                                                 timer.diff_times['generate_goal_response'],
    #                                                 timer.diff_times[plan_name]])

    #         save_all(None, test_graphs, srp._goal_instances, plans, current_trial, args.output_dir)

    #         global_index += len(srp._goal_instances)
    #         avg_time = (diff + (global_index - last_trial) * avg_time) / (global_index - last_trial + 1)
    #         print('----------------------')
    #         logger.info('avg_time: {}'.format(avg_time))
    #         logger.info('Trial: {} ({} remaining)'.format(global_index, num_trials - global_index))
    #         logger.info('Estimated time remaining: {}'.format(secs_to_str((num_trials - global_index) * avg_time)))
    #         logger.info('Percent completed: {}%'.format(100.0 * (global_index) / num_trials))
    #         print('----------------------')

    print(timer.diff_times)


if __name__ == '__main__':
    logger.info('Simulation Experiment starting up... #BOLD')
    try:
        main()
    finally:
        logger.info('Simulation Experiment stopping... #BOLD')
